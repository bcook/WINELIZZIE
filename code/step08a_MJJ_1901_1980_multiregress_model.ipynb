{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script will develop and test a multiple regression model for GHD-Core using the following predictors:\n",
    "#### CRU Instrumental Temperature, Precipitation, PDSI\n",
    "\n",
    "#### Season: May-June-July (MJJ)\n",
    "#### Years: 1901-1980"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reset the python session to clear out all variables, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import all the various python modules that I will need in order to run the analyses and generate the figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Modules and define functions\n",
    "import calendar\n",
    "import os\n",
    "import numpy as np\n",
    "import netCDF4\n",
    "import matplotlib\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from IPython.display import display\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "#sns.set(palette=\"Set5\")\n",
    "\n",
    "# STATSMODELS Package: needed for multiple regression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Embeds plots inside the notebook (use in iPython Notebook)\n",
    "%matplotlib inline\n",
    "\n",
    "# For plotting a rectangle on the maps\n",
    "def plot_rectangle(bmap, lonmin,lonmax,latmin,latmax):\n",
    "    xs = [lonmin,lonmax,lonmax,lonmin,lonmin]\n",
    "    ys = [latmin,latmin,latmax,latmax,latmin]\n",
    "    bmap.plot(xs, ys,latlon = True, color='k', linestyle='--', linewidth=3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Set some various user variables.\n",
    "* Load the GHD-Core data and set season and years to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup the Analysis\n",
    "\n",
    "# User Set Variables (knobs)\n",
    "# Months to average (climate data)\n",
    "mons_ave = [5,6,7]; mons_ave_txt = 'MJJ';\n",
    "yr1 = np.array([1901]); yr2 = np.array([1980])  \n",
    "\n",
    "# Rectangle Boundaries (Also the region over which I will spatially average the CRU data)\n",
    "lonmin=-2; lonmax=8; latmin=43; latmax=51;\n",
    "\n",
    "# Cru Lat/Lon Range (boundaries for the Map)\n",
    "lat1_cru = np.array([27]);   lat2_cru = np.array([71])   \n",
    "lon1_cru = np.array([-12]);  lon2_cru = np.array([45])  \n",
    "\n",
    "# GHD Data: All Sites I want to Analyze\n",
    "ghd_all_names=[ 'GHDcore',\\\n",
    "            ]\n",
    "\n",
    "# Load formatted GHD anomaly data into a dataframe\n",
    "infile= '../data/ghd_anom_doy_v02.csv'   # Name of the original data file\n",
    "df=pd.read_csv(infile)\n",
    "\n",
    "# Pull out the year vector\n",
    "yr = np.int64(df.Year)\n",
    "\n",
    "# Load lat/lon data for individual Sites\n",
    "infile = '../data/site_locs.csv'   # Name of the data file\n",
    "df_sitelocs=pd.read_csv(infile)\n",
    "df_sitelocs.index=df_sitelocs.Location\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this cell, I will load and seasonally average/sum the CRU temperature and precipitation data. As part of this, I am creating month and year vectors so that I can pull the specific data I want. This is a more or less global dataset, so I also trim the latitude and longitude ranges for just Europe, where the GHD data is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 5)\n",
      "(1, 6)\n",
      "(2, 7)\n"
     ]
    }
   ],
   "source": [
    "# LOAD CRU TEMP PRECIP Data. These are from version 3.21 of the CRU Climate Grids.\n",
    "\n",
    "# Create vectors for years and months\n",
    "mon_cru = np.arange(1,13); mon_all = np.transpose(np.tile(mon_cru,(1,112)))\n",
    "yr_cru  = np.arange(1901,2013); yr_all = np.transpose(np.tile(yr_cru,(12,1))); yr_all = np.reshape(yr_all,(1344,1))\n",
    "\n",
    "# Open and Load Data from a NetCDF File\n",
    "ncfile_tmp = netCDF4.Dataset('/Users/bcook/Documents/GEODATA/cru321/cru_ts3.21.1901.2012.tmp.dat.nc')\n",
    "ncfile_pre = netCDF4.Dataset('/Users/bcook/Documents/GEODATA/cru321/cru_ts3.21.1901.2012.pre.dat.nc')\n",
    "\n",
    "# Load in the dimension variables\n",
    "lon = ncfile_tmp.variables['lon'][:]\n",
    "lat = ncfile_tmp.variables['lat'][:]\n",
    "\n",
    "# Just load region I want to look at\n",
    "# Yr/Lat/Lon Location for Grid Cell I want\n",
    "i_lat = np.where((lat>=lat1_cru) & (lat<=lat2_cru)); i_lat=i_lat[0]\n",
    "i_lon = np.where((lon>=lon1_cru) & (lon<=lon2_cru)); i_lon=i_lon[0]\n",
    "\n",
    "# Initialize Matrices for Climate Variables\n",
    "tmp_month = np.zeros((np.size(mons_ave),np.size(yr_cru),np.size(i_lat),np.size(i_lon)))\n",
    "pre_month = np.zeros((np.size(mons_ave),np.size(yr_cru),np.size(i_lat),np.size(i_lon)))\n",
    "\n",
    "# Load this region for the months requested\n",
    "for i in enumerate(mons_ave):\n",
    "    # Location for all instances of the current month    \n",
    "    loc_mon = np.where(mon_all==i[1]); loc_mon=loc_mon[0];\n",
    "\n",
    "    # These files are organized: time, lat, lon\n",
    "    tmp=ncfile_tmp.variables['tmp'][loc_mon,i_lat,i_lon];\n",
    "    pre=ncfile_pre.variables['pre'][loc_mon,i_lat,i_lon];\n",
    "\n",
    "    # Store the Monthly Data\n",
    "    tmp_month[i[0],:,:,:] = tmp\n",
    "    pre_month[i[0],:,:,:] = pre    \n",
    "    \n",
    "    print(i)\n",
    "\n",
    "# Now calculate seasonal average/sum\n",
    "tmp_seas_ave = np.nanmean(tmp_month,axis=0)\n",
    "pre_seas_sum = np.nansum(pre_month,axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Just like the previous cell, but here I load the PDSI data, calculated from the CRU climate grids by Gerard van der Schier. The files are in a bit of a different format, so this had to be its' own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bcook/Documents/GEODATA/cru321/pdsi.3.21.penman.snow.1901-1910.nc\n",
      "/Users/bcook/Documents/GEODATA/cru321/pdsi.3.21.penman.snow.1911-1920.nc\n",
      "/Users/bcook/Documents/GEODATA/cru321/pdsi.3.21.penman.snow.1911-1920.nc\n",
      "/Users/bcook/Documents/GEODATA/cru321/pdsi.3.21.penman.snow.1931-1940.nc\n",
      "/Users/bcook/Documents/GEODATA/cru321/pdsi.3.21.penman.snow.1941-1950.nc\n",
      "/Users/bcook/Documents/GEODATA/cru321/pdsi.3.21.penman.snow.1951-1960.nc\n",
      "/Users/bcook/Documents/GEODATA/cru321/pdsi.3.21.penman.snow.1961-1970.nc\n",
      "/Users/bcook/Documents/GEODATA/cru321/pdsi.3.21.penman.snow.1971-1980.nc\n",
      "/Users/bcook/Documents/GEODATA/cru321/pdsi.3.21.penman.snow.1981-1990.nc\n",
      "/Users/bcook/Documents/GEODATA/cru321/pdsi.3.21.penman.snow.1991-2000.nc\n",
      "/Users/bcook/Documents/GEODATA/cru321/pdsi.3.21.penman.snow.2001-2010.nc\n",
      "/Users/bcook/Documents/GEODATA/cru321/pdsi.3.21.penman.snow.2011-2012.nc\n",
      "(0, 5)\n",
      "(1, 6)\n",
      "(2, 7)\n"
     ]
    }
   ],
   "source": [
    "# LOAD CRU scPDSI Data. These are based on 3.21 of the CRU Climate Grids, calculated by Gerard van der Schrier.\n",
    "\n",
    "# Create vectors for years and months\n",
    "mon_cru = np.arange(1,13);      mon_all = np.transpose(np.tile(mon_cru,(1,112)))\n",
    "yr_cru  = np.arange(1901,2013); yr_all  = np.transpose(np.tile(yr_cru,(12,1))); yr_all = np.reshape(yr_all,(1344,1))\n",
    "\n",
    "# PDSI data\n",
    "root_dir = '/Users/bcook/Documents/GEODATA/cru321/'\n",
    "\n",
    "# CRU PDSI are split up among different files, so I will have to load each one\n",
    "# individually\n",
    "files_crupdsi = ['pdsi.3.21.penman.snow.1901-1910.nc', \\\n",
    "    'pdsi.3.21.penman.snow.1911-1920.nc',\\\n",
    "    'pdsi.3.21.penman.snow.1911-1920.nc',\\\n",
    "    'pdsi.3.21.penman.snow.1931-1940.nc',\\\n",
    "    'pdsi.3.21.penman.snow.1941-1950.nc',\\\n",
    "    'pdsi.3.21.penman.snow.1951-1960.nc',\\\n",
    "    'pdsi.3.21.penman.snow.1961-1970.nc',\\\n",
    "    'pdsi.3.21.penman.snow.1971-1980.nc',\\\n",
    "    'pdsi.3.21.penman.snow.1981-1990.nc',\\\n",
    "    'pdsi.3.21.penman.snow.1991-2000.nc',\\\n",
    "    'pdsi.3.21.penman.snow.2001-2010.nc',\\\n",
    "    'pdsi.3.21.penman.snow.2011-2012.nc'\\\n",
    "    ]\n",
    "\n",
    "# Load in the dimension variables\n",
    "fname = root_dir+files_crupdsi[0]\n",
    "ncfile_pdsi = netCDF4.Dataset(fname)\n",
    "lon = ncfile_pdsi.variables['lon'][:]\n",
    "lat = ncfile_pdsi.variables['lat'][:]\n",
    "ncfile_pdsi.close\n",
    "\n",
    "# Trim lons/lats\n",
    "i_lat = np.where((lat>=lat1_cru) & (lat<=lat2_cru)); i_lat=i_lat[0]\n",
    "i_lon = np.where((lon>=lon1_cru) & (lon<=lon2_cru)); i_lon=i_lon[0]\n",
    "lon_map = lon[i_lon]; lat_map = lat[i_lat];\n",
    "\n",
    "# Load Each file separately\n",
    "for ifile in np.arange(0,np.size(files_crupdsi)):\n",
    "    \n",
    "    # Current File Name/Open netcdf object\n",
    "    fname = root_dir+files_crupdsi[ifile]; print(fname)\n",
    "    ncfile_pdsi = netCDF4.Dataset(fname)\n",
    "    pdsi = np.float64(ncfile_pdsi.variables['pdsi'][:,i_lat,i_lon]);\n",
    "\n",
    "    # Concatenate into a complete array for all files\n",
    "    if ifile==0:\n",
    "        pdsi_all=pdsi;\n",
    "    else:\n",
    "        pdsi_all=np.concatenate((pdsi_all,pdsi),axis=0)\n",
    "\n",
    "    # Close netcdf file\n",
    "    ncfile_pdsi.close\n",
    "\n",
    "#sns.plt.plot(pdsi_all[:,44,60])\n",
    "\n",
    "# Now pull out and calculate seasonal averages\n",
    "# Initialize Matrices for Climate Variables\n",
    "pdsi_month = np.zeros((np.size(mons_ave),np.size(yr_cru),np.size(i_lat),np.size(i_lon)))\n",
    "\n",
    "# Load this region for the months requested\n",
    "for i in enumerate(mons_ave):\n",
    "    print(i)\n",
    "    # Location for all instances of the current month    \n",
    "    loc_mon = np.where(mon_all==i[1]); loc_mon=loc_mon[0];\n",
    "\n",
    "    # Store in a new matrix\n",
    "    pdsi_month[i[0],:,:,:] = pdsi_all[loc_mon,:,:]\n",
    "\n",
    "# Seasonal average PDSI\n",
    "pdsi_seas = np.nanmean(pdsi_month,axis=0)\n",
    "\n",
    "# Delete Variables I don't need anymore\n",
    "del(pdsi_month)\n",
    "del(pdsi_all)\n",
    "del(pdsi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* All the data should now be loaded. This cell just does a quick check to make sure the format of the climate data looks okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the climate data is now loaded, and averaged to create the seasonal average/sums.\n",
      "They should be arrayed as: yr x lat x lon \n",
      "\n",
      "Yrs: 1901-2012\n",
      "Lat: 27.25 to 70.75\n",
      "Lon: -11.75 to 44.75\n",
      "\n",
      "Temp Array Size: (112, 88, 114)\n",
      "Prec Array Size: (112, 88, 114)\n",
      "PDSI Array Size: (112, 88, 114)\n"
     ]
    }
   ],
   "source": [
    "# All the data should now be loaded by this point\n",
    "# Location (indices) of Years to Correlate\n",
    "# \n",
    "print('All the climate data is now loaded, and averaged to create the seasonal average/sums.')\n",
    "print('They should be arrayed as: yr x lat x lon ')\n",
    "print('')\n",
    "print('Yrs: '+np.str(np.min(yr_cru))+'-'+np.str(np.max(yr_cru)))\n",
    "print('Lat: '+np.str(np.min(lat_map))+' to '+np.str(np.max(lat_map)))\n",
    "print('Lon: '+np.str(np.min(lon_map))+' to '+np.str(np.max(lon_map)))\n",
    "print('')\n",
    "print('Temp Array Size: '+np.str(tmp_seas_ave.shape))\n",
    "print('Prec Array Size: '+np.str(pre_seas_sum.shape))\n",
    "print('PDSI Array Size: '+np.str(pdsi_seas.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For the regression analyses, I need time series. This next cell will calculate regional average time series (cosine area weighted by latitude) from the CRU data. For GHD-Core, I pick a big area that encompasses most of France."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'GHDcore')\n",
      "lat range = (43 to 51)\n",
      "lon range = (-2 to 8)\n"
     ]
    }
   ],
   "source": [
    "# Calculate Regional Averages for CRU Data around each of the GHD Locations. For the Core and Composite Indices,\n",
    "# use a large region covering France.\n",
    "\n",
    "# Arrays to store regional average PDSI/Temp/Precip for each site\n",
    "pdsi_coswtmean = np.zeros((np.size(yr_cru),np.size(ghd_all_names)))\n",
    "tmp_coswtmean  = np.zeros((np.size(yr_cru),np.size(ghd_all_names)))\n",
    "pre_coswtmean  = np.zeros((np.size(yr_cru),np.size(ghd_all_names)))\n",
    "\n",
    "# Loop through each site individually.\n",
    "for ifile in enumerate(ghd_all_names):\n",
    "    # Counter\n",
    "    print(ifile)\n",
    "    \n",
    "    # Pull GHD Site Coordinates (if specific site)\n",
    "    #        Dummy Coorindates for Core and Composite Index\n",
    "    if ifile[1] in ['GHDcore','GHDmean']:\n",
    "        \n",
    "        # Latitude/Longitude range for averaging\n",
    "        print(\"lat range = (\"+np.str(latmin)+\" to \"+np.str(latmax)+\")\")\n",
    "        print(\"lon range = (\"+np.str(lonmin)+\" to \"+np.str(lonmax)+\")\")\n",
    "       \n",
    "        i_lat_reg = np.where((lat_map>=latmin) & (lat_map<=latmax)); i_lat_reg=i_lat_reg[0]\n",
    "        i_lon_reg = np.where((lon_map>=lonmin) & (lon_map<=lonmax)); i_lon_reg=i_lon_reg[0]\n",
    "\n",
    "        # Latitude and Longitude Indices for this region\n",
    "        lon_reg = lon_map[i_lon_reg]\n",
    "        lat_reg = lat_map[i_lat_reg]\n",
    "\n",
    "        # Create Latitude Weights\n",
    "        lat_wts = scipy.cos(scipy.deg2rad(lat_reg));\n",
    "        lat_wts_grid,lon_junk = np.meshgrid(lat_wts,lon_reg)\n",
    "        lat_wts_grid=np.swapaxes(lat_wts_grid,1,0)\n",
    "        \n",
    "    # Load Each Year and Spatially Average\n",
    "    for i_yr in enumerate(yr_cru):\n",
    "        #print(i_yr)\n",
    "        # Pull out Current Month Temp/Precip\n",
    "        pdsi_curr = pdsi_seas[i_yr[0],i_lat_reg,:][:,i_lon_reg]\n",
    "        temp_curr = tmp_seas_ave[i_yr[0],i_lat_reg,:][:,i_lon_reg]\n",
    "        prec_curr = pre_seas_sum[i_yr[0],i_lat_reg,:][:,i_lon_reg]\n",
    "\n",
    "        # Mask ocean cells\n",
    "        prec_curr[prec_curr>=100000]=np.nan\n",
    "        temp_curr[temp_curr>=100000]=np.nan\n",
    "        pdsi_curr[pdsi_curr>=100000]=np.nan\n",
    "        \n",
    "        # Cosine Weighted Average\n",
    "        pdsi_coswtmean[i_yr[0],ifile[0]] = np.ma.average(np.ma.masked_invalid(pdsi_curr),weights=lat_wts_grid)\n",
    "        tmp_coswtmean[i_yr[0],ifile[0]]  = np.ma.average(np.ma.masked_invalid(temp_curr),weights=lat_wts_grid)\n",
    "        pre_coswtmean[i_yr[0],ifile[0]]  = np.ma.average(np.ma.masked_invalid(prec_curr),weights=lat_wts_grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Analysis: GHD-Core\n",
    "* I am going to conduct single variable regressions, and multivariate regressions using temperature and different combinations of prec and temp. The first thing I will do, however, is set up a dataframe to store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "      <th>x1 (p)</th>\n",
       "      <th>x2 (p)</th>\n",
       "      <th>x3 (p)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prec</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDSI</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp+Prec</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp+PDSI</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp+Prec+PDSI</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp+Prec+(Tmp x Pre)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp+PDSI+(Tmp x PDSI)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         R2  AIC  BIC x1 (p) x2 (p) x3 (p)\n",
       "Temp                    NaN  NaN  NaN    NaN    NaN    NaN\n",
       "Prec                    NaN  NaN  NaN    NaN    NaN    NaN\n",
       "PDSI                    NaN  NaN  NaN    NaN    NaN    NaN\n",
       "Temp+Prec               NaN  NaN  NaN    NaN    NaN    NaN\n",
       "Temp+PDSI               NaN  NaN  NaN    NaN    NaN    NaN\n",
       "Temp+Prec+PDSI          NaN  NaN  NaN    NaN    NaN    NaN\n",
       "Temp+Prec+(Tmp x Pre)   NaN  NaN  NaN    NaN    NaN    NaN\n",
       "Temp+PDSI+(Tmp x PDSI)  NaN  NaN  NaN    NaN    NaN    NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe to store regression results\n",
    "\n",
    "# Column Headers\n",
    "df_cols =   [   'R2',\\\n",
    "                'AIC',\\\n",
    "                'BIC',\\\n",
    "                'x1 (p)',\\\n",
    "                'x2 (p)',\\\n",
    "                'x3 (p)',\\\n",
    "            ]\n",
    "\n",
    "# Row labels\n",
    "df_rows =   [   'Temp',\\\n",
    "                'Prec',\\\n",
    "                'PDSI',\\\n",
    "                'Temp+Prec',\\\n",
    "                'Temp+PDSI',\\\n",
    "                'Temp+Prec+PDSI',\\\n",
    "                'Temp+Prec+(Tmp x Pre)',\\\n",
    "                'Temp+PDSI+(Tmp x PDSI)',\\\n",
    "           ]\n",
    "\n",
    "# Create the dataframe-at this point, it should just be filled with NaN placeholders.\n",
    "df_regress = pd.DataFrame(index=df_rows,columns=df_cols)\n",
    "df_regress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull out climate and GHD time series for just the years that I want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pull out the relevant time series for the years I want (climate and GHD)\n",
    "# Non detrended data\n",
    "# Year Locations of the GHD data and climate data.\n",
    "loc_yrs_ghd = np.where((yr>=yr1)     & (yr<=yr2))[0];\n",
    "loc_yrs_cru = np.where((yr_cru>=yr1) & (yr_cru<=yr2))[0];\n",
    "\n",
    "# Pull out GHD\n",
    "ghd=df.GHDcore; ghd=ghd[loc_yrs_ghd];\n",
    " \n",
    "# Pull out Climate Data\n",
    "tmp_series  = tmp_coswtmean[loc_yrs_cru]\n",
    "pre_series  = pre_coswtmean[loc_yrs_cru]\n",
    "pdsi_series = pdsi_coswtmean[loc_yrs_cru]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEMPERATURE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## REGRESSION TEMPERATURE PREDICTOR ONLY---------------------------------------------\n",
    "# Remember to manually add a constant term\n",
    "predictor_array      = np.zeros([np.size(tmp_series),1])*np.nan   \n",
    "predictor_array[:,0] = tmp_series[:,0]\n",
    "predictor_array      = sm.tools.add_constant(predictor_array)\n",
    "\n",
    "model = sm.OLS(ghd,predictor_array)\n",
    "results = model.fit()\n",
    "\n",
    "# Pull out relevant information from the regression\n",
    "R2     = np.round(results.rsquared,decimals=3)\n",
    "AIC    = np.round(results.aic,decimals=2)\n",
    "BIC    = np.round(results.bic,decimals=2)\n",
    "x1     = np.round(results.params.x1,decimals=2)\n",
    "x1_p   = np.round(results.pvalues.x1,decimals=5)\n",
    "x1_str = np.str(x1)+' ('+np.str(x1_p)+')'\n",
    "\n",
    "# Store data in this dataframe\n",
    "df_regress.values[0,0] = R2\n",
    "df_regress.values[0,1] = AIC\n",
    "df_regress.values[0,2] = BIC\n",
    "df_regress.values[0,3] = x1_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRECIPITATION REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## REGRESSION PRECIPITATION PREDICTOR ONLY---------------------------------------------\n",
    "# Remember to manually add a constant term\n",
    "predictor_array      = np.zeros([np.size(pre_series),1])*np.nan   \n",
    "predictor_array[:,0] = pre_series[:,0]\n",
    "predictor_array      = sm.tools.add_constant(predictor_array)\n",
    "\n",
    "model = sm.OLS(ghd,predictor_array)\n",
    "results = model.fit()\n",
    "\n",
    "# Pull out relevant information from the regression\n",
    "R2     = np.round(results.rsquared,decimals=3)\n",
    "AIC    = np.round(results.aic,decimals=2)\n",
    "BIC    = np.round(results.bic,decimals=2)\n",
    "x1     = np.round(results.params.x1,decimals=2)\n",
    "x1_p   = np.round(results.pvalues.x1,decimals=5)\n",
    "x1_str = np.str(x1)+' ('+np.str(x1_p)+')'\n",
    "\n",
    "# Store data in this dataframe\n",
    "df_regress.values[1,0] = R2\n",
    "df_regress.values[1,1] = AIC\n",
    "df_regress.values[1,2] = BIC\n",
    "df_regress.values[1,3] = x1_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDSI REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## REGRESSION PDSI PREDICTOR ONLY---------------------------------------------\n",
    "# Remember to manually add a constant term\n",
    "predictor_array      = np.zeros([np.size(pdsi_series),1])*np.nan   \n",
    "predictor_array[:,0] = pdsi_series[:,0]\n",
    "predictor_array      = sm.tools.add_constant(predictor_array)\n",
    "\n",
    "model = sm.OLS(ghd,predictor_array)\n",
    "results = model.fit()\n",
    "\n",
    "# Pull out relevant information from the regression\n",
    "R2     = np.round(results.rsquared,decimals=3)\n",
    "AIC    = np.round(results.aic,decimals=2)\n",
    "BIC    = np.round(results.bic,decimals=2)\n",
    "x1     = np.round(results.params.x1,decimals=2)\n",
    "x1_p   = np.round(results.pvalues.x1,decimals=5)\n",
    "x1_str = np.str(x1)+' ('+np.str(x1_p)+')'\n",
    "\n",
    "# Store data in this dataframe\n",
    "df_regress.values[2,0] = R2\n",
    "df_regress.values[2,1] = AIC\n",
    "df_regress.values[2,2] = BIC\n",
    "df_regress.values[2,3] = x1_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEMPERATURE+PRECIPITATION REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## REGRESSION TEMP+PREC ONLY---------------------------------------------\n",
    "# I need to manually add a constant term\n",
    "predictor_array      = np.zeros([np.size(tmp_series),2])*np.nan   \n",
    "predictor_array[:,0] = tmp_series[:,0]\n",
    "predictor_array[:,1] = pre_series[:,0]\n",
    "predictor_array      = sm.tools.add_constant(predictor_array)\n",
    "\n",
    "model = sm.OLS(ghd,predictor_array)\n",
    "results = model.fit()\n",
    "\n",
    "# Pull out relevant information from the regression\n",
    "R2     = np.round(results.rsquared,decimals=3)\n",
    "AIC    = np.round(results.aic,decimals=2)\n",
    "BIC    = np.round(results.bic,decimals=2)\n",
    "\n",
    "x1     = np.round(results.params.x1,decimals=2)\n",
    "x1_p   = np.round(results.pvalues.x1,decimals=5)\n",
    "x1_str = np.str(x1)+' ('+np.str(x1_p)+')'\n",
    "\n",
    "x2     = np.round(results.params.x2,decimals=2)\n",
    "x2_p   = np.round(results.pvalues.x2,decimals=5)\n",
    "x2_str = np.str(x2)+' ('+np.str(x2_p)+')'\n",
    "\n",
    "# Store data in this dataframe\n",
    "df_regress.values[3,0] = R2\n",
    "df_regress.values[3,1] = AIC\n",
    "df_regress.values[3,2] = BIC\n",
    "df_regress.values[3,3] = x1_str\n",
    "df_regress.values[3,4] = x2_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEMPERATURE+PDSI REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## REGRESSION TEMP+PDSI ONLY---------------------------------------------\n",
    "# I need to manually add a constant term\n",
    "predictor_array      = np.zeros([np.size(tmp_series),2])*np.nan   \n",
    "predictor_array[:,0] = tmp_series[:,0]\n",
    "predictor_array[:,1] = pdsi_series[:,0]\n",
    "predictor_array      = sm.tools.add_constant(predictor_array)\n",
    "\n",
    "model = sm.OLS(ghd,predictor_array)\n",
    "results = model.fit()\n",
    "\n",
    "# Pull out relevant information from the regression\n",
    "R2     = np.round(results.rsquared,decimals=3)\n",
    "AIC    = np.round(results.aic,decimals=2)\n",
    "BIC    = np.round(results.bic,decimals=2)\n",
    "\n",
    "x1     = np.round(results.params.x1,decimals=2)\n",
    "x1_p   = np.round(results.pvalues.x1,decimals=5)\n",
    "x1_str = np.str(x1)+' ('+np.str(x1_p)+')'\n",
    "\n",
    "x2     = np.round(results.params.x2,decimals=2)\n",
    "x2_p   = np.round(results.pvalues.x2,decimals=5)\n",
    "x2_str = np.str(x2)+' ('+np.str(x2_p)+')'\n",
    "\n",
    "# Store data in this dataframe\n",
    "df_regress.values[4,0] = R2\n",
    "df_regress.values[4,1] = AIC\n",
    "df_regress.values[4,2] = BIC\n",
    "df_regress.values[4,3] = x1_str\n",
    "df_regress.values[4,4] = x2_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEMPERATURE+PRECIPITATION+PDSI REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## REGRESSION TEMP+PREC+PDSI ONLY---------------------------------------------\n",
    "# I need to manually add a constant term\n",
    "predictor_array      = np.zeros([np.size(tmp_series),3])*np.nan   \n",
    "predictor_array[:,0] = tmp_series[:,0]\n",
    "predictor_array[:,1] = pre_series[:,0]\n",
    "predictor_array[:,2] = pdsi_series[:,0]\n",
    "predictor_array      = sm.tools.add_constant(predictor_array)\n",
    "\n",
    "model   = sm.OLS(ghd,predictor_array)\n",
    "results = model.fit()\n",
    "\n",
    "# Pull out relevant information from the regression\n",
    "R2     = np.round(results.rsquared,decimals=3)\n",
    "AIC    = np.round(results.aic,decimals=2)\n",
    "BIC    = np.round(results.bic,decimals=2)\n",
    "\n",
    "x1     = np.round(results.params.x1,decimals=2)\n",
    "x1_p   = np.round(results.pvalues.x1,decimals=5)\n",
    "x1_str = np.str(x1)+' ('+np.str(x1_p)+')'\n",
    "\n",
    "x2     = np.round(results.params.x2,decimals=2)\n",
    "x2_p   = np.round(results.pvalues.x2,decimals=5)\n",
    "x2_str = np.str(x2)+' ('+np.str(x2_p)+')'\n",
    "\n",
    "x3     = np.round(results.params.x3,decimals=2)\n",
    "x3_p   = np.round(results.pvalues.x3,decimals=5)\n",
    "x3_str = np.str(x3)+' ('+np.str(x3_p)+')'\n",
    "\n",
    "# Store data in this dataframe\n",
    "df_regress.values[5,0] = R2\n",
    "df_regress.values[5,1] = AIC\n",
    "df_regress.values[5,2] = BIC\n",
    "df_regress.values[5,3] = x1_str\n",
    "df_regress.values[5,4] = x2_str\n",
    "df_regress.values[5,5] = x3_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEMPERATURE+PRECIPITATION+(Temp/Prec Interaction) REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## REGRESSION TEMP+PREC+PDSI ONLY---------------------------------------------\n",
    "# I need to manually add a constant term\n",
    "predictor_array      = np.zeros([np.size(tmp_series),3])*np.nan   \n",
    "predictor_array[:,0] = tmp_series[:,0]\n",
    "predictor_array[:,1] = pre_series[:,0]\n",
    "predictor_array[:,2] = tmp_series[:,0]*pre_series[:,0]\n",
    "predictor_array      = sm.tools.add_constant(predictor_array)\n",
    "\n",
    "model   = sm.OLS(ghd,predictor_array)\n",
    "results = model.fit()\n",
    "\n",
    "# Pull out relevant information from the regression\n",
    "R2     = np.round(results.rsquared,decimals=3)\n",
    "AIC    = np.round(results.aic,decimals=2)\n",
    "BIC    = np.round(results.bic,decimals=2)\n",
    "\n",
    "x1     = np.round(results.params.x1,decimals=2)\n",
    "x1_p   = np.round(results.pvalues.x1,decimals=5)\n",
    "x1_str = np.str(x1)+' ('+np.str(x1_p)+')'\n",
    "\n",
    "x2     = np.round(results.params.x2,decimals=2)\n",
    "x2_p   = np.round(results.pvalues.x2,decimals=5)\n",
    "x2_str = np.str(x2)+' ('+np.str(x2_p)+')'\n",
    "\n",
    "x3     = np.round(results.params.x3,decimals=2)\n",
    "x3_p   = np.round(results.pvalues.x3,decimals=5)\n",
    "x3_str = np.str(x3)+' ('+np.str(x3_p)+')'\n",
    "\n",
    "# Store data in this dataframe\n",
    "df_regress.values[6,0] = R2\n",
    "df_regress.values[6,1] = AIC\n",
    "df_regress.values[6,2] = BIC\n",
    "df_regress.values[6,3] = x1_str\n",
    "df_regress.values[6,4] = x2_str\n",
    "df_regress.values[6,5] = x3_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEMPERATURE+PDSI+(Temp/PDSI Interaction) REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## REGRESSION TEMP+PREC+PDSI ONLY---------------------------------------------\n",
    "# I need to manually add a constant term\n",
    "predictor_array      = np.zeros([np.size(tmp_series),3])*np.nan   \n",
    "predictor_array[:,0] = tmp_series[:,0]\n",
    "predictor_array[:,1] = pdsi_series[:,0]\n",
    "predictor_array[:,2] = tmp_series[:,0]*pdsi_series[:,0]\n",
    "predictor_array      = sm.tools.add_constant(predictor_array)\n",
    "\n",
    "model   = sm.OLS(ghd,predictor_array)\n",
    "results = model.fit()\n",
    "\n",
    "# Pull out relevant information from the regression\n",
    "R2     = np.round(results.rsquared,decimals=3)\n",
    "AIC    = np.round(results.aic,decimals=2)\n",
    "BIC    = np.round(results.bic,decimals=2)\n",
    "\n",
    "x1     = np.round(results.params.x1,decimals=2)\n",
    "x1_p   = np.round(results.pvalues.x1,decimals=5)\n",
    "x1_str = np.str(x1)+' ('+np.str(x1_p)+')'\n",
    "\n",
    "x2     = np.round(results.params.x2,decimals=2)\n",
    "x2_p   = np.round(results.pvalues.x2,decimals=5)\n",
    "x2_str = np.str(x2)+' ('+np.str(x2_p)+')'\n",
    "\n",
    "x3     = np.round(results.params.x3,decimals=2)\n",
    "x3_p   = np.round(results.pvalues.x3,decimals=5)\n",
    "x3_str = np.str(x3)+' ('+np.str(x3_p)+')'\n",
    "\n",
    "# Store data in this dataframe\n",
    "df_regress.values[7,0] = R2\n",
    "df_regress.values[7,1] = AIC\n",
    "df_regress.values[7,2] = BIC\n",
    "df_regress.values[7,3] = x1_str\n",
    "df_regress.values[7,4] = x2_str\n",
    "df_regress.values[7,5] = x3_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  \n",
      "                  \n",
      "REGRESSION RESULTS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "      <th>x1 (p)</th>\n",
       "      <th>x2 (p)</th>\n",
       "      <th>x3 (p)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>0.704</td>\n",
       "      <td>421.72</td>\n",
       "      <td>426.48</td>\n",
       "      <td>-6.04 (0.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prec</th>\n",
       "      <td>0.241</td>\n",
       "      <td>496.99</td>\n",
       "      <td>501.75</td>\n",
       "      <td>0.07 (0.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDSI</th>\n",
       "      <td>0.133</td>\n",
       "      <td>507.7</td>\n",
       "      <td>512.46</td>\n",
       "      <td>1.68 (0.00089)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp+Prec</th>\n",
       "      <td>0.713</td>\n",
       "      <td>421.27</td>\n",
       "      <td>428.41</td>\n",
       "      <td>-5.66 (0.0)</td>\n",
       "      <td>0.02 (0.12563)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp+PDSI</th>\n",
       "      <td>0.706</td>\n",
       "      <td>423.08</td>\n",
       "      <td>430.23</td>\n",
       "      <td>-5.9 (0.0)</td>\n",
       "      <td>0.24 (0.4359)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp+Prec+PDSI</th>\n",
       "      <td>0.713</td>\n",
       "      <td>423.26</td>\n",
       "      <td>432.79</td>\n",
       "      <td>-5.67 (0.0)</td>\n",
       "      <td>0.02 (0.18964)</td>\n",
       "      <td>-0.02 (0.94624)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp+Prec+(Tmp x Pre)</th>\n",
       "      <td>0.717</td>\n",
       "      <td>422.2</td>\n",
       "      <td>431.73</td>\n",
       "      <td>-3.9 (0.03591)</td>\n",
       "      <td>0.16 (0.27037)</td>\n",
       "      <td>-0.01 (0.31657)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp+PDSI+(Tmp x PDSI)</th>\n",
       "      <td>0.708</td>\n",
       "      <td>424.53</td>\n",
       "      <td>434.05</td>\n",
       "      <td>-6.14 (0.0)</td>\n",
       "      <td>4.06 (0.44165)</td>\n",
       "      <td>-0.24 (0.46842)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           R2     AIC     BIC          x1 (p)          x2 (p)  \\\n",
       "Temp                    0.704  421.72  426.48     -6.04 (0.0)             NaN   \n",
       "Prec                    0.241  496.99  501.75      0.07 (0.0)             NaN   \n",
       "PDSI                    0.133   507.7  512.46  1.68 (0.00089)             NaN   \n",
       "Temp+Prec               0.713  421.27  428.41     -5.66 (0.0)  0.02 (0.12563)   \n",
       "Temp+PDSI               0.706  423.08  430.23      -5.9 (0.0)   0.24 (0.4359)   \n",
       "Temp+Prec+PDSI          0.713  423.26  432.79     -5.67 (0.0)  0.02 (0.18964)   \n",
       "Temp+Prec+(Tmp x Pre)   0.717   422.2  431.73  -3.9 (0.03591)  0.16 (0.27037)   \n",
       "Temp+PDSI+(Tmp x PDSI)  0.708  424.53  434.05     -6.14 (0.0)  4.06 (0.44165)   \n",
       "\n",
       "                                 x3 (p)  \n",
       "Temp                                NaN  \n",
       "Prec                                NaN  \n",
       "PDSI                                NaN  \n",
       "Temp+Prec                           NaN  \n",
       "Temp+PDSI                           NaN  \n",
       "Temp+Prec+PDSI          -0.02 (0.94624)  \n",
       "Temp+Prec+(Tmp x Pre)   -0.01 (0.31657)  \n",
       "Temp+PDSI+(Tmp x PDSI)  -0.24 (0.46842)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"                  \")\n",
    "print(\"                  \")\n",
    "print(\"REGRESSION RESULTS\")\n",
    "df_regress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictor_array      = np.zeros([np.size(tmp_series),3])*np.nan   \n",
    "predictor_array[:,0] = tmp_series[:,0]\n",
    "predictor_array[:,1] = pre_series[:,0]\n",
    "predictor_array[:,2] = pdsi_series[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.61641030e+01,   1.83988983e+02,  -6.95196608e-01],\n",
       "       [  1.41644164e+01,   1.93765062e+02,  -1.00649784e+00],\n",
       "       [  1.47939009e+01,   2.43210655e+02,  -1.08864630e+00],\n",
       "       [  1.65363880e+01,   1.82431306e+02,  -1.26110351e+00],\n",
       "       [  1.58818375e+01,   1.92479404e+02,  -1.95642044e+00],\n",
       "       [  1.53848876e+01,   1.34320995e+02,  -1.80184117e+00],\n",
       "       [  1.44780076e+01,   2.08453153e+02,  -2.00562414e+00],\n",
       "       [  1.61110024e+01,   2.29382903e+02,  -1.38138184e+00],\n",
       "       [  1.40949652e+01,   2.12171158e+02,  -8.81438429e-01],\n",
       "       [  1.44956591e+01,   2.85954419e+02,   1.57503569e+00],\n",
       "       [  1.65546708e+01,   1.88348924e+02,  -9.56207400e-01],\n",
       "       [  1.54400258e+01,   2.17781601e+02,   7.48297873e-02],\n",
       "       [  1.47877470e+01,   2.15855585e+02,   1.82205870e-01],\n",
       "       [  1.45174120e+01,   2.70715107e+02,   8.82911201e-01],\n",
       "       [  1.60582811e+01,   2.48426991e+02,   8.70065660e-01],\n",
       "       [  1.47482395e+01,   2.07129043e+02,   8.17371066e-01],\n",
       "       [  1.68147814e+01,   2.74549810e+02,   1.27811925e+00],\n",
       "       [  1.54484242e+01,   1.79806783e+02,  -1.03783821e+00],\n",
       "       [  1.50126093e+01,   1.43298868e+02,  -1.05514019e+00],\n",
       "       [  1.57855623e+01,   1.96887080e+02,  -6.31939391e-01],\n",
       "       [  1.69413005e+01,   1.49538866e+02,  -9.56207400e-01],\n",
       "       [  1.58121323e+01,   1.81105039e+02,   7.48297873e-02],\n",
       "       [  1.52930853e+01,   1.62926699e+02,   1.82205870e-01],\n",
       "       [  1.60867846e+01,   2.07043638e+02,   8.82911201e-01],\n",
       "       [  1.57795237e+01,   2.21312070e+02,   8.70065660e-01],\n",
       "       [  1.45019999e+01,   2.57004427e+02,   8.17371066e-01],\n",
       "       [  1.56097858e+01,   2.47716289e+02,   1.27811925e+00],\n",
       "       [  1.58960696e+01,   1.48246392e+02,  -1.03783821e+00],\n",
       "       [  1.60821313e+01,   1.99470094e+02,  -1.05514019e+00],\n",
       "       [  1.55221782e+01,   3.04636906e+02,  -6.31939391e-01],\n",
       "       [  1.62219475e+01,   2.20274204e+02,   1.84022439e+00],\n",
       "       [  1.48331355e+01,   3.06757700e+02,   1.04520486e+00],\n",
       "       [  1.57381570e+01,   2.02905658e+02,  -1.59242624e+00],\n",
       "       [  1.69032727e+01,   1.39726122e+02,  -2.17626611e+00],\n",
       "       [  1.57856525e+01,   1.70241175e+02,  -2.37575726e-01],\n",
       "       [  1.52992705e+01,   2.58258097e+02,   1.97643145e+00],\n",
       "       [  1.63347389e+01,   1.88958037e+02,   6.55277822e-01],\n",
       "       [  1.50536360e+01,   2.17677827e+02,  -1.52393078e+00],\n",
       "       [  1.47505283e+01,   2.23156620e+02,   3.59350905e-01],\n",
       "       [  1.56277550e+01,   2.43021385e+02,   7.36690385e-01],\n",
       "       [  1.52496197e+01,   2.41900620e+02,   1.47662797e+00],\n",
       "       [  1.58135050e+01,   1.94829854e+02,  -1.01175347e+00],\n",
       "       [  1.65168316e+01,   1.84600151e+02,  -2.30479317e+00],\n",
       "       [  1.57054330e+01,   1.68919370e+02,  -2.74086372e+00],\n",
       "       [  1.74945583e+01,   1.55422207e+02,  -2.13953166e+00],\n",
       "       [  1.58954989e+01,   2.25701158e+02,  -1.87412817e+00],\n",
       "       [  1.77320806e+01,   1.61570923e+02,  -2.42444839e+00],\n",
       "       [  1.55243390e+01,   2.26513551e+02,  -1.26063529e+00],\n",
       "       [  1.61856167e+01,   1.48572192e+02,  -3.67505003e+00],\n",
       "       [  1.74383279e+01,   1.69258921e+02,  -2.06328224e+00],\n",
       "       [  1.51772658e+01,   2.72375916e+02,   1.59472361e+00],\n",
       "       [  1.74463251e+01,   1.29022978e+02,  -1.13966422e+00],\n",
       "       [  1.59047931e+01,   2.28395703e+02,  -1.82358916e+00],\n",
       "       [  1.48517618e+01,   1.85317606e+02,  -2.60395070e+00],\n",
       "       [  1.58494958e+01,   2.40874147e+02,  -1.23820808e+00],\n",
       "       [  1.51226097e+01,   2.13054227e+02,  -1.49202630e+00],\n",
       "       [  1.54054668e+01,   2.33686716e+02,  -1.00520791e+00],\n",
       "       [  1.56218183e+01,   2.61542659e+02,   7.61442640e-01],\n",
       "       [  1.70384094e+01,   1.57665008e+02,  -4.82856814e-01],\n",
       "       [  1.62015546e+01,   2.20884872e+02,  -1.84259975e-01],\n",
       "       [  1.54567053e+01,   1.86369009e+02,  -6.26416315e-01],\n",
       "       [  1.48223766e+01,   1.47791789e+02,  -9.05429864e-01],\n",
       "       [  1.53566169e+01,   2.22142121e+02,  -3.29850544e-01],\n",
       "       [  1.69146681e+01,   1.55032770e+02,  -1.65113508e+00],\n",
       "       [  1.49991394e+01,   2.21719407e+02,  -2.19156107e-01],\n",
       "       [  1.54755674e+01,   2.11400771e+02,   1.53747495e+00],\n",
       "       [  1.58161216e+01,   1.70237247e+02,  -6.84421290e-01],\n",
       "       [  1.49476288e+01,   2.24547627e+02,   4.43447635e-01],\n",
       "       [  1.55869398e+01,   2.32490503e+02,   7.65885702e-01],\n",
       "       [  1.59862433e+01,   1.86728005e+02,  -1.17476062e-01],\n",
       "       [  1.59849704e+01,   2.58541455e+02,  -1.57869484e-01],\n",
       "       [  1.45596161e+01,   2.09356062e+02,  -9.47964176e-01],\n",
       "       [  1.61657366e+01,   2.36938821e+02,  -1.82512037e+00],\n",
       "       [  1.51349573e+01,   1.84640103e+02,  -1.31942227e+00],\n",
       "       [  1.55118893e+01,   1.87990543e+02,  -6.24059434e-01],\n",
       "       [  1.78772671e+01,   1.20427690e+02,  -2.89016959e+00],\n",
       "       [  1.46921307e+01,   3.32870568e+02,   2.62178734e+00],\n",
       "       [  1.46722361e+01,   2.22460978e+02,   1.20948067e+00],\n",
       "       [  1.56433939e+01,   1.82604429e+02,   8.50623946e-01],\n",
       "       [  1.41711807e+01,   2.70180141e+02,   9.24932304e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ghd_array      = np.zeros([np.size(tmp_series),1])*np.nan   \n",
    "ghd_array[:,0] = ghd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -9.61713869],\n",
       "       [  3.02571845],\n",
       "       [  4.01143274],\n",
       "       [-10.40285298],\n",
       "       [ -8.25999583],\n",
       "       [ -8.01713869],\n",
       "       [  2.58286131],\n",
       "       [ -7.61713869],\n",
       "       [ -1.55999583],\n",
       "       [  1.02539042],\n",
       "       [-13.96839949],\n",
       "       [ -2.25589949],\n",
       "       [ -4.24979512],\n",
       "       [ -0.54231412],\n",
       "       [-10.05170012],\n",
       "       [  3.44829988],\n",
       "       [-12.01777348],\n",
       "       [ -3.80534655],\n",
       "       [ -5.68089949],\n",
       "       [ -6.29339949],\n",
       "       [-11.76248941],\n",
       "       [ -7.94820369],\n",
       "       [  0.33751059],\n",
       "       [ -6.74820369],\n",
       "       [ -2.41963226],\n",
       "       [ -0.89339949],\n",
       "       [ -8.21963226],\n",
       "       [ -4.51963226],\n",
       "       [ -6.16248941],\n",
       "       [ -2.76248941],\n",
       "       [ -3.87313262],\n",
       "       [  6.78160051],\n",
       "       [ -5.62122369],\n",
       "       [-14.66408083],\n",
       "       [ -3.89265226],\n",
       "       [ -1.52122369],\n",
       "       [-11.5355094 ],\n",
       "       [ -1.26408083],\n",
       "       [  2.72163345],\n",
       "       [ -3.50589949],\n",
       "       [  1.60660051],\n",
       "       [ -7.64339949],\n",
       "       [-12.43089949],\n",
       "       [ -5.64339949],\n",
       "       [-17.87602799],\n",
       "       [ -4.14339949],\n",
       "       [-13.48856726],\n",
       "       [ -3.41836679],\n",
       "       [ -7.25170012],\n",
       "       [ -9.94571012],\n",
       "       [  4.34410051],\n",
       "       [-11.51839949],\n",
       "       [ -5.33089949],\n",
       "       [  5.00660051],\n",
       "       [ -1.19339949],\n",
       "       [  9.00660051],\n",
       "       [ -1.43089949],\n",
       "       [  0.46910051],\n",
       "       [-10.34339949],\n",
       "       [ -8.28089949],\n",
       "       [ -8.58089949],\n",
       "       [  5.21910051],\n",
       "       [  4.30660051],\n",
       "       [ -6.63089949],\n",
       "       [  5.19410051],\n",
       "       [ -4.83089949],\n",
       "       [ -2.66839949],\n",
       "       [  0.94410051],\n",
       "       [ -0.55589949],\n",
       "       [ -2.10589949],\n",
       "       [ -5.83089949],\n",
       "       [  7.23160051],\n",
       "       [ -3.33089949],\n",
       "       [ -0.96839949],\n",
       "       [ -2.56839949],\n",
       "       [-16.66839949],\n",
       "       [  4.49540058],\n",
       "       [  6.42397201],\n",
       "       [ -1.29339949],\n",
       "       [  8.21910051]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ghd_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
